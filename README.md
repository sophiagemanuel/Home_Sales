# Overview

- This project utilizes PySpark to analyze homes dales data with the primary goal of determining key metrics about home sales. This analysis included creating temporary views, partitioning data, caching tables, and comparing query runtimes.

- Ensure you have Google Colab, Java, Spark, PySpark. Set environment variables, read in data, create temporary view, and run SQL Queries.

- This analysis uses PySpark to efficiently process and analyze home sales data. By caching and partitioning data, we can significantly reduce query runtimes and improve preformance. This approach is scalable and can be applied to larger datasets in real-world scenarios. 
